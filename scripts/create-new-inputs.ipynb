{
 "metadata": {
  "name": "",
  "signature": "sha256:1ba71e08b08a5234dfffab0f97a1a021d894824584863ec33616510f3a0ace88"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Overview\n",
      "\n",
      "I want to create a sample data set of 100 grid cells (10km x 10km)\n",
      "near Fairbanks. I will use actual data where I can easily find it\n",
      "and otherise I will generate random data. This sample dataset will \n",
      "demonstrate the correct \"shape\" (variables and their dimensions) for \n",
      "the ** new** input files to dvm-dos-tem.\n",
      "\n",
      "## Summary of Requirements\n",
      "\n",
      "* Data should be in a rectangular (grid) layout.\n",
      "* NetCDF.\n",
      "* Attempting to conform to CF & COARDS standards.\n",
      "* Geospatial information must be with the file. Each file should\n",
      "have variables for Lat and Lon each defined interms of the\n",
      "dimensions of (y, x), where (y, x) are the rectangular grid \n",
      "coordinates.\n",
      "\n",
      "> Is computing GIRR the only place that latitude is needed?\n",
      "\n",
      "> Maybe it is possible to precompute GIRR?\n",
      "\n",
      "> Is longitude even used?  \n",
      "\n",
      "# Process\n",
      "\n",
      "## Driving climate file (nirr, vapo, tair, prec)\n",
      "\n",
      "\n",
      "First step is to pick some y,x or lat/lon bounding box coordinates \n",
      "to use with `gdal_translate` for subsetting the AIEM domain \n",
      "data files from SNAP. The files I have from SNAP are in Alaska Albers\n",
      "projection, 1km pixel size.\n",
      "\n",
      "With Google Maps, I take a guess at where the Bonanza Creek LTER is from\n",
      "the sattelite view (64.667557, -148.489804), and then eyeball the location \n",
      "~5km north and west of there (64.708950, -148.633313) so that my new \n",
      "subwindow is more or less centered on the LTER site."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Working with a netcdf file as opposed to the tif, I can use `ncview` to \n",
      "quickly check coordinates and data values to make sure the commands are \n",
      "doing what I expect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Specifying the \"creation option\" means that special \n",
      "# variables will be written to the new netcdf file mapping\n",
      "# row/column coordinates to lat/lon\n",
      "!gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" \\\n",
      "../../snap-data/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_01_2001.tif \\\n",
      "temporary.nc\n",
      "\n",
      "# see what we got\n",
      "#!ncdump -h temporary.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While `gdal_translate` would let me specify the coordinates for my\n",
      "subwindow in lon/lat, (projection coordinates), for some reason I want\n",
      "a nice, square, 10x10km data set, so I use the row/column coordinates\n",
      "that I find using `ncview`: (64.708950, -148.633313) which is roughly\n",
      "(j=1134, i=991) as far as `ncview` is concerned. `gdal_translate` wants\n",
      "the \"source window\" defined in terms of (xoff, yoff, xsize, ysize).\n",
      "\n",
      "If I was not concerned with the exact pixel size of the sample dataset\n",
      "I could instead speficy the \"source window\" to `gdal_translate` using\n",
      "\"projection coordinates\", assuming the source file has the right geo-\n",
      "spatial information with it.\n",
      "\n",
      "Anyways, use `gdal_translate` again to grab the sub-window, specifying \n",
      "the coordinates with pixel and line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" \\\n",
      "-srcwin 991 1134 10 10 temporary.nc temporary2.nc\n",
      "\n",
      "# Check out what we got\n",
      "# !ncdump -h temporary2.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import netCDF4\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_veg_classification(fname, sizey=10, sizex=10):\n",
      "    ncfile = netCDF4.Dataset(fname, mode='w', format='NETCDF4')\n",
      "\n",
      "    Y = ncfile.createDimension('Y', sizey)\n",
      "    X = ncfile.createDimension('X', sizex)\n",
      "\n",
      "    veg_class = ncfile.createVariable('veg_class', np.int, ('Y', 'X',))\n",
      "    veg_class[:] = np.random.uniform(low=1, high=7, size=(10,10))\n",
      "\n",
      "    ncfile.close()\n",
      "\n",
      "# Create a new veg_classification file\n",
      "make_veg_classification(\"new-veg-dataset.nc\", sizey=10, sizex=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_run_mask(filename, sizey=10, sizex=10):\n",
      "    ncfile = netCDF4.Dataset(filename, mode='w', format='NETCDF4')\n",
      "    Y = ncfile.createDimension('Y', sizey)\n",
      "    X = ncfile.createDimension('X', sizex)\n",
      "\n",
      "    run = ncfile.createVariable('run', np.int, ('Y', 'X',))\n",
      "    run[:] = np.ones((10,10))\n",
      "    \n",
      "    ncfile.close()\n",
      "\n",
      "# Create a new run mask file (all ones for now)\n",
      "make_run_mask('run-mask.nc', sizey=10, sizex=10)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def copy_co2_to_new_style(filename):\n",
      "    '''Creates an co2 file for dvmdostem from the old sample data'''\n",
      "    old_ncfile = netCDF4.Dataset(\"../DATA/test_single_site/dataregion/co2.nc\", mode='r')\n",
      "    new_ncfile = netCDF4.Dataset(filename, mode='w', format='NETCDF4')\n",
      "\n",
      "    # Dimensions\n",
      "    yearD = new_ncfile.createDimension('year', None) # append along time axis\n",
      "    \n",
      "    # Coordinate Variable\n",
      "    yearV = new_ncfile.createVariable('year', np.int, ('year',))\n",
      "    \n",
      "    # Data Variables\n",
      "    co2 = new_ncfile.createVariable('co2', np.float32, ('year',))\n",
      "    \n",
      "    yearV[:] = old_ncfile.variables['YEAR'][:]\n",
      "    co2[:] = old_ncfile.variables['CO2'][:]\n",
      "    \n",
      "    old_ncfile.close()\n",
      "    new_ncfile.close()\n",
      "    \n",
      "# Copy over the co2 file\n",
      "copy_co2_to_new_style('new-co2-dataset.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_empty_climate_nc_file(filename, sizey=10, sizex=10):\n",
      "    '''Creates an empty climate file for dvmdostem; y,x grid, time unlimited.'''\n",
      "    \n",
      "    ncfile = netCDF4.Dataset(filename, mode=\"w\", format='NETCDF4')\n",
      "    \n",
      "    # Dimensions for the file.\n",
      "    time_dim = ncfile.createDimension('time', None) # append along time axis\n",
      "    Y = ncfile.createDimension('Y', sizey)\n",
      "    X = ncfile.createDimension('X', sizex)\n",
      "\n",
      "    # Coordinate Variables\n",
      "    Y = ncfile.createVariable('Y', np.int, ('Y',))\n",
      "    X = ncfile.createVariable('X', np.int, ('X',))\n",
      "    Y[:] = np.arange(0, sizey)\n",
      "    X[:] = np.arange(0, sizex)\n",
      "    \n",
      "    # 'Spatial Refefence' variables (?)\n",
      "    lat = ncfile.createVariable('lat', np.float32, ('Y', 'X',))\n",
      "    lon = ncfile.createVariable('lon', np.float32, ('Y', 'X',))\n",
      "    \n",
      "    # Create data variables\n",
      "    #co2 = ncfile.createVariable('co2', np.float32, ('time')) # actually year\n",
      "    temp_air = ncfile.createVariable('tair', np.float32, ('time', 'Y', 'X',))\n",
      "    precip = ncfile.createVariable('precip', np.float32, ('time', 'Y', 'X',))\n",
      "    nirr = ncfile.createVariable('nirr', np.float32, ('time', 'Y', 'X',))\n",
      "    vapor_press = ncfile.createVariable('vapor_press', np.float32, ('time', 'Y', 'X',))\n",
      "    \n",
      "    ncfile.close()\n",
      "    \n",
      "# Make a new file to copy data into\n",
      "create_empty_climate_nc_file('new-climate-dataset.nc', sizey=10, sizex=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open the 'temporary' dataset\n",
      "temporary = netCDF4.Dataset('temporary2.nc', mode='r')\n",
      "\n",
      "# Open the new file for appending\n",
      "new_climatedateset = netCDF4.Dataset('new-climate-dataset.nc', mode='a')\n",
      "\n",
      "# Grab the lat and lon from the temporary file\n",
      "lat = new_climatedateset.variables['lat']\n",
      "lon = new_climatedateset.variables['lon']\n",
      "lat[:] = temporary.variables['lat'][:]\n",
      "lon[:] = temporary.variables['lon'][:]\n",
      "\n",
      "#tair = new_climatedateset.variables['tair']\n",
      "#tair[0,:,:] = temporary.variables['Band1'][:]\n",
      "\n",
      "new_climatedateset.close()\n",
      "temporary.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!ncdump -h temporary2.nc\n",
      "#!ncdump temporary2.nc\n",
      "!ncdump new-climate-dataset.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we have a basic dataset with the lat/lon coordinates. Time to populate it with bit of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "YEARS = 2\n",
      "\n",
      "TIMESTEPS=YEARS*12\n",
      "\n",
      "# Write random, junk data to the climate file\n",
      "new_climatedataset = netCDF4.Dataset('new-climate-dataset.nc', mode='a')\n",
      "\n",
      "sx = new_climatedataset.variables['X'].size\n",
      "sy = new_climatedataset.variables['Y'].size\n",
      "\n",
      "junkA = np.random.uniform(low=0.0, high=10, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
      "junkB = np.random.uniform(low=0.0, high=1300, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
      "junkC = np.random.uniform(low=0.0, high=20, size=(TIMESTEPS*sy*sx)).reshape(TIMESTEPS, sy, sx)\n",
      "\n",
      "new_climatedataset.variables['precip'][:] = junkA\n",
      "new_climatedataset.variables['nirr'][:] = junkB\n",
      "new_climatedataset.variables['vapor_press'][:] = junkC\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open the new file for appending\n",
      "new_climatedataset = netCDF4.Dataset('new-climate-dataset.nc', mode='a')\n",
      "\n",
      "for yridx, year in enumerate(range(2001, 2001+YEARS)):\n",
      "    for midx, month in enumerate(range (1,13)): # Note 1 based month!\n",
      "        \n",
      "        # TRANSLATE TO NETCDF\n",
      "        # The curly braces are needed to run the shell command from w/in\n",
      "        # ipython and have the variable exansion with year and month\n",
      "        # work out alright\n",
      "        !gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" \\\n",
      "        {\"../../snap-data/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_2001_2100/tas_mean_C_iem_cccma_cgcm3_1_sresa1b_%02d_%04d.tif\" % (month, year)} \\\n",
      "        temporary.nc\n",
      "        \n",
      "        !gdal_translate -of netCDF -co \"WRITE_LONLAT=YES\" \\\n",
      "        -srcwin 991 1134 10 10 temporary.nc temporary2.nc\n",
      "        \n",
      "        t2 = netCDF4.Dataset('temporary2.nc', mode='r')\n",
      "\n",
      "        # Grab the lat and lon from the temporary file\n",
      "        tair = new_climatedateset.variables['tair']\n",
      "        tair[yridx*12+midx] = t2.variables['Band1'][:]\n",
      "        \n",
      "        t2.close()\n",
      "\n",
      "print \"Done appending. Closing the new file\"\n",
      "new_climatedateset.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ncdump -h new-climate-dataset.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}